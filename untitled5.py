# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xEoKHse9OPxRzLMtiB7nMZ2M9f7B0WTG
"""

# Colab setup: run at top
!nvidia-smi || true

# Install Kaggle CLI and required libs
!pip install --upgrade pip
!pip install kaggle tensorflow scikit-learn matplotlib seaborn tqdm

# Imports
import os
import math
import json
import random
import shutil
import numpy as np
import matplotlib.pyplot as plt
from glob import glob
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import classification_report, confusion_matrix
import itertools
from collections import Counter
print("TensorFlow version:", tf.__version__)

import kagglehub
import os

# Download latest version
path = kagglehub.dataset_download("abdallahalidev/plantvillage-dataset")

print("Path to dataset files:", path)

# The repo extracts to a folder named like "plantvillage dataset" (verify)
for d in os.listdir(path):
    if 'plantvillage' in d.lower():
        dataset_root = os.path.join(path, d)
        break
else:
    raise FileNotFoundError("Couldn't find the extracted dataset directory. Check the zip/unzip step output.")

print("Found dataset root:", dataset_root)

# Inspect basic structure
for root, dirs, files in os.walk(dataset_root):
    print(root, "->", len(dirs), "dirs", len(files), "files")
    break

# Adjust if dataset path differs (e.g., dataset_root + "/color")
image_dir = os.path.join(dataset_root, "color")
if not os.path.exists(image_dir):
    # try other common path
    image_dir = dataset_root

print("Using image_dir =", image_dir)
IMG_SIZE = 224           # EfficientNetB0 default-ish; can increase to 240/260 for other models
BATCH_SIZE = 32
SEED = 42
AUTOTUNE = tf.data.AUTOTUNE

# Training schedule
INITIAL_EPOCHS = 10
FINE_TUNE_EPOCHS = 10
TOTAL_EPOCHS = INITIAL_EPOCHS + FINE_TUNE_EPOCHS

# Create training and validation datasets using image_dataset_from_directory
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    image_dir,
    labels='inferred',
    label_mode='int',
    validation_split=0.2,
    subset='training',
    seed=SEED,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    image_dir,
    labels='inferred',
    label_mode='int',
    validation_split=0.2,
    subset='validation',
    seed=SEED,
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)

class_names = train_ds.class_names
num_classes = len(class_names)
print("Classes:", class_names, "Num classes:", num_classes)

# Create a small test dataset from a fraction of validation for quick evaluation (optional)
# Shuffle+prefetch for performance
train_ds = train_ds.shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)

# Compute class weights from train_ds
train_labels = []
for images, labels in train_ds.unbatch():
    train_labels.append(int(labels.numpy()))
counts = Counter(train_labels)
print("Train class counts sample:", counts)
total = sum(counts.values())
class_weight = {i: (total / (num_classes * counts.get(i,1))) for i in range(num_classes)}
print("Class weights:", class_weight)

# Data augmentation layer (on GPU)
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.15),
    layers.RandomZoom(0.15),
    layers.RandomContrast(0.1),
], name="data_augmentation")

# Preprocessing function for model
preprocess_input = tf.keras.applications.efficientnet.preprocess_input

# Build model with MobileNetV2 transfer learning
base_model = tf.keras.applications.MobileNetV2(
    include_top=False,
    input_shape=(IMG_SIZE, IMG_SIZE, 3),
    weights='imagenet'
)
base_model.trainable = False  # freeze initial layers

# Preprocess for MobileNet
preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input

inputs = keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
x = data_augmentation(inputs)
x = preprocess_input(x)
x = base_model(x, training=False)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dropout(0.3)(x)
x = layers.Dense(256, activation='relu')(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.3)(x)
outputs = layers.Dense(num_classes, activation='softmax')(x)

model = keras.Model(inputs, outputs, name="plant_disease_mobilenet")
model.summary()

initial_lr = 1e-3
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=initial_lr),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

callbacks = [
    keras.callbacks.ModelCheckpoint("best_model_initial.h5", save_best_only=True, monitor="val_accuracy"),
    keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3, min_lr=1e-6, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=6, restore_best_weights=True)
]

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=INITIAL_EPOCHS,
    callbacks=callbacks,
    class_weight=class_weight
)

# Unfreeze the top layers of the base model for fine-tuning
base_model.trainable = True

# Freeze all layers except the top N layers to avoid catastrophic forgetting
fine_tune_at = int(len(base_model.layers) * 0.6)  # unfreeze last 40% of layers
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True

# Recompile with lower LR for fine-tuning
fine_lr = 1e-5
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=fine_lr),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

callbacks_fine = [
    keras.callbacks.ModelCheckpoint("best_model_finetuned.h5", save_best_only=True, monitor="val_accuracy"),
    keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-7, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
]

history_fine = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=TOTAL_EPOCHS,
    initial_epoch=history.epoch[-1] + 1,
    callbacks=callbacks_fine,
    class_weight=class_weight
)

# Unfreeze the top layers of the base model for fine-tuning
base_model.trainable = True

# Freeze all layers except the top N layers to avoid catastrophic forgetting
fine_tune_at = int(len(base_model.layers) * 0.6)  # unfreeze last 40% of layers
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False
for layer in base_model.layers[fine_tune_at:]:
    layer.trainable = True

# Recompile with lower LR for fine-tuning
fine_lr = 1e-5
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=fine_lr),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

callbacks_fine = [
    keras.callbacks.ModelCheckpoint("best_model_finetuned.h5", save_best_only=True, monitor="val_accuracy"),
    keras.callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-7, verbose=1),
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)
]

history_fine = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=TOTAL_EPOCHS,
    initial_epoch=history.epoch[-1] + 1,
    callbacks=callbacks_fine,
    class_weight=class_weight
)

# Gather true labels and predictions on validation set
y_true = []
y_pred = []
y_pred_probs = []

for images, labels in val_ds.unbatch():
    img = tf.expand_dims(images, 0)
    probs = model.predict(img, verbose=0)[0]
    pred = np.argmax(probs)
    y_pred.append(int(pred))
    y_pred_probs.append(probs)
    y_true.append(int(labels.numpy()))

print("Val accuracy (computed):", np.mean(np.array(y_pred) == np.array(y_true)))

# Classification report
print(classification_report(y_true, y_pred, target_names=class_names, digits=4))

# Confusion matrix
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(10,8))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=90)
plt.yticks(tick_marks, class_names)
thresh = cm.max() / 2.
for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    plt.text(j, i, format(cm[i, j], 'd'),
             horizontalalignment="center",
             color="white" if cm[i, j] > thresh else "black")
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()
plt.show()

# Save TF SavedModel
model.save("plant_disease_saved_model")

# Optional: TFLite conversion (for edge deployment)
converter = tf.lite.TFLiteConverter.from_saved_model("plant_disease_saved_model")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
open("plant_disease_model.tflite","wb").write(tflite_model)
print("Saved SavedModel and TFLite model")

